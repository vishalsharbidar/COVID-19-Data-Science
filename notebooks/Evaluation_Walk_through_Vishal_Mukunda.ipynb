{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One run full walktrhough "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do the full walk through on the large data set\n",
    "* Refactor the source code and bring it to individual scripts\n",
    "* Ensure a full run with one click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid-19'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'The system cannot find the path specified.\\r\\n'\n",
      "out : b''\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/get_data.py\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( 'data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 53928\n",
      " Latest date is: 2020-08-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# %load src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    df_code = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')\n",
    "    df = 'data/raw/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/08-22-2020.csv'\n",
    "    \n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "    \n",
    "    #Confirmed death and recovered\n",
    "    pd_CRD=pd.read_csv(df)\n",
    "    data = pd_CRD.drop({'FIPS', 'Confirmed', 'Admin2','Province_State', 'Last_Update', 'Lat', 'Long_', 'Combined_Key', 'Incidence_Rate', 'Case-Fatality_Ratio'}, axis=1).rename(columns={'Country_Region':'COUNTRY'}).set_index('COUNTRY')\n",
    "    #data.head()\n",
    "    \n",
    "    time_idx = pd_raw.columns[4:]\n",
    "    df_plot = pd.DataFrame({\n",
    "        'date':time_idx})\n",
    "    df_input_large= pd_raw['Country/Region'].unique()\n",
    "    for each in df_input_large:\n",
    "        df_plot[each] =np.array(pd_raw[pd_raw['Country/Region']==each].iloc[:,4::].sum(axis=0))\n",
    "    df = df_plot.drop('date', axis=1)\n",
    "    \n",
    "    #Merging the data set over COUNTRY for CODE column\n",
    "    world_raw =  pd.DataFrame({\"COUNTRY\" : df_input_large, \"Confirm cases\" :df.iloc[-1]})\n",
    "    world = pd.merge(world_raw, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    world_con = pd.merge(world, data, on = \"COUNTRY\")\n",
    "    world_con.to_csv('data/processed/COVID_CRD.csv',sep=';',index=False)\n",
    "    #print(world_con)\n",
    "    \n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'COUNTRY',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model_1=pd_data_base.set_index(['state','COUNTRY']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "    pd_relational_model = pd.merge(pd_relational_model_1, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    \n",
    "    pd_relational_model.to_csv('data/processed/20200823_COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    \n",
    "    #print(df_input_large)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "            date state  COUNTRY  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "30816 2020-01-22    no  Germany          0                 0.0           NaN   \n",
      "30817 2020-01-23    no  Germany          0                 0.0           NaN   \n",
      "30818 2020-01-24    no  Germany          0                 0.0           NaN   \n",
      "30819 2020-01-25    no  Germany          0                 0.2           NaN   \n",
      "30820 2020-01-26    no  Germany          0                 1.0           NaN   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "30816                    NaN  \n",
      "30817                    NaN  \n",
      "30818                    NaN  \n",
      "30819                    NaN  \n",
      "30820                    NaN  \n"
     ]
    }
   ],
   "source": [
    "# %load src/features/build_features.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','COUNTRY',filter_on]].groupby(['state','COUNTRY']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','COUNTRY']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['COUNTRY']=='Germany'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd_result_larg[pd_result_larg['COUNTRY']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal Sharbidar\\Desktop\\ADS_COVID-19\\ads_covid-19\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly import tools\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "world_con=pd.read_csv('data/processed/COVID_CRD.csv',sep=';')\n",
    "conca = pd.merge(df_input_large, world_con, on = \"COUNTRY\"  )\n",
    "\n",
    "fig = go.Figure()\n",
    "fig_2 = go.Figure()\n",
    "fig_3 = go.Figure(go.Choropleth(\n",
    "                locations = conca['CODE'],\n",
    "                z = conca['confirmed'],\n",
    "                text = conca['COUNTRY'],\n",
    "                colorscale = 'Blues',\n",
    "                autocolorscale=False,\n",
    "                reversescale=False,\n",
    "                marker_line_color='darkgray',\n",
    "                marker_line_width=0.5,\n",
    "                colorbar_title = 'Confirmed cases',\n",
    "                ))\n",
    "\n",
    "fig_3.update_layout(title_text='COVID 19 WORLD MAP',\n",
    "                    width=1700,\n",
    "                    height=720,\n",
    "                    geo=dict(\n",
    "                        showframe=True,\n",
    "                        showcoastlines=True,\n",
    "                        projection_type='equirectangular'\n",
    "                    ),\n",
    "                    annotations = [dict(\n",
    "                        x=0.55,\n",
    "                        y=0.1,\n",
    "                        xref='paper',\n",
    "                        yref='paper',\n",
    "                        text='World Map',\n",
    "                        showarrow = False\n",
    "                    )]\n",
    "                )\n",
    "\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.title = 'COVID-19 Dashboard'\n",
    "\n",
    "app.layout = html.Div([\n",
    "        \n",
    "        dbc.Row(dbc.Col(html.H3('Enterprise Data Science COVID-19 Data Analytics'),\n",
    "                        width={'size': 6, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "        \n",
    "        dbc.Row(dbc.Col(html.Div('''\n",
    "                            Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "                            it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "                            filtering and machine learning to approximating the doubling time, and\n",
    "                            (static) deployment of responsive dashboard. \n",
    "                            '''),\n",
    "                        width={'size': 10, 'offset': 1},\n",
    "                        )\n",
    "                ),\n",
    "        \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown',\n",
    "                            options=[ {'label': each,'value':each} for each in df_input_large['COUNTRY'].unique()],\n",
    "                            value=['US', 'Germany','India'], # which are pre-selected\n",
    "                            multi= True),\n",
    "                        width={'size': 5, \"offset\": 0, 'order': 1}\n",
    "                        ),\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown_2',\n",
    "                            options=[ {'label': each,'value':each} for each in df_input_large['COUNTRY'].unique()],\n",
    "                            value='Germany', # which are pre-selected\n",
    "                            multi= False),\n",
    "                        width={'size': 5, \"offset\": 1, 'order': 2}\n",
    "                        ),\n",
    "                ], no_gutters=True\n",
    "        ),\n",
    "    \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                        dcc.Dropdown(\n",
    "                            id='doubling_time',\n",
    "                            options=[\n",
    "                                {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "                                {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "                                {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                                {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "                            ],\n",
    "                            value='confirmed',\n",
    "                            multi=False\n",
    "                            ),\n",
    "                        width={'size': 3, \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                dbc.Col(\n",
    "                        dcc.Dropdown(\n",
    "                            id='doubling_time_2',\n",
    "                            options=[\n",
    "                                {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "                                {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "                                {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                                {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "                            ],\n",
    "                            value='confirmed_DR',\n",
    "                            multi=False\n",
    "                            ),\n",
    "                        width={'size': 3, \"offset\": 3, 'order': 'second'}\n",
    "                        ),\n",
    "                \n",
    "                ], no_gutters=True\n",
    "        ),\n",
    "                \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig, \n",
    "                            id='main_window_slope'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                \n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig_2, \n",
    "                            id='SIR_model'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 0, 'order': 'last'}\n",
    "                        ),\n",
    "            ]\n",
    "        ),\n",
    "    \n",
    "        dbc.Row(\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig_3,\n",
    "                            id='World_map'\n",
    "                        ),\n",
    "                        width=12, md={'size': 12,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "         )\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_dropdown', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['COUNTRY']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=900,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        ) \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "'''@app.callback(\n",
    "    Output('SIR_model', 'figure'),\n",
    "    [Input('country_dropdown_2', 'value')])\n",
    "\n",
    "def SIR_figure(country_list,show_doubling):\n",
    "    \n",
    "    return {}'''\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, port= 8051, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>confirmed_filtered</th>\n",
       "      <th>confirmed_DR</th>\n",
       "      <th>confirmed_filtered_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55677</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5482416</td>\n",
       "      <td>5485525.0</td>\n",
       "      <td>137.401816</td>\n",
       "      <td>126.795074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55943</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5529824</td>\n",
       "      <td>5529390.4</td>\n",
       "      <td>119.859707</td>\n",
       "      <td>126.987354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56223</th>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5573847</td>\n",
       "      <td>5575147.8</td>\n",
       "      <td>120.937005</td>\n",
       "      <td>123.406568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56476</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5622540</td>\n",
       "      <td>5621358.6</td>\n",
       "      <td>120.268425</td>\n",
       "      <td>121.244059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56742</th>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>no</td>\n",
       "      <td>US</td>\n",
       "      <td>5667112</td>\n",
       "      <td>5667569.4</td>\n",
       "      <td>120.541818</td>\n",
       "      <td>121.645992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date state COUNTRY  confirmed  confirmed_filtered  confirmed_DR  \\\n",
       "83     2020-01-22    no      US          1                 0.4           NaN   \n",
       "347    2020-01-23    no      US          1                 1.3           NaN   \n",
       "615    2020-01-24    no      US          2                 2.2      2.666667   \n",
       "881    2020-01-25    no      US          2                 3.0      3.333333   \n",
       "1146   2020-01-26    no      US          5                 3.8      2.000000   \n",
       "...           ...   ...     ...        ...                 ...           ...   \n",
       "55677  2020-08-18    no      US    5482416           5485525.0    137.401816   \n",
       "55943  2020-08-19    no      US    5529824           5529390.4    119.859707   \n",
       "56223  2020-08-20    no      US    5573847           5575147.8    120.937005   \n",
       "56476  2020-08-21    no      US    5622540           5621358.6    120.268425   \n",
       "56742  2020-08-22    no      US    5667112           5667569.4    120.541818   \n",
       "\n",
       "       confirmed_filtered_DR  \n",
       "83                       NaN  \n",
       "347                      NaN  \n",
       "615                      NaN  \n",
       "881                      NaN  \n",
       "1146                     NaN  \n",
       "...                      ...  \n",
       "55677             126.795074  \n",
       "55943             126.987354  \n",
       "56223             123.406568  \n",
       "56476             121.244059  \n",
       "56742             121.645992  \n",
       "\n",
       "[214 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_large[df_input_large['COUNTRY']==\"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
