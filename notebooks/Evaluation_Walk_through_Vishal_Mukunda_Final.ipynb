{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One run full walktrhough "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do the full walk through on the large data set\n",
    "* Refactor the source code and bring it to individual scripts\n",
    "* Ensure a full run with one click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid-19'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b'The system cannot find the path specified.\\r\\n'\n",
      "out : b''\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( 'data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan' 'Albania' 'Algeria' 'Andorra' 'Angola'\n",
      " 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Australia' 'Austria'\n",
      " 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus'\n",
      " 'Belgium' 'Belize' 'Benin' 'Bhutan' 'Bolivia' 'Bosnia and Herzegovina'\n",
      " 'Botswana' 'Brazil' 'Brunei' 'Bulgaria' 'Burkina Faso' 'Burma' 'Burundi'\n",
      " 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada' 'Central African Republic'\n",
      " 'Chad' 'Chile' 'China' 'Colombia' 'Comoros' 'Congo (Brazzaville)'\n",
      " 'Congo (Kinshasa)' 'Costa Rica' \"Cote d'Ivoire\" 'Croatia' 'Cuba' 'Cyprus'\n",
      " 'Czechia' 'Denmark' 'Diamond Princess' 'Djibouti' 'Dominica'\n",
      " 'Dominican Republic' 'Ecuador' 'Egypt' 'El Salvador' 'Equatorial Guinea'\n",
      " 'Eritrea' 'Estonia' 'Eswatini' 'Ethiopia' 'Fiji' 'Finland' 'France'\n",
      " 'Gabon' 'Gambia' 'Georgia' 'Germany' 'Ghana' 'Greece' 'Grenada'\n",
      " 'Guatemala' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti' 'Holy See'\n",
      " 'Honduras' 'Hungary' 'Iceland' 'India' 'Indonesia' 'Iran' 'Iraq'\n",
      " 'Ireland' 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan'\n",
      " 'Kenya' 'Korea, South' 'Kosovo' 'Kuwait' 'Kyrgyzstan' 'Laos' 'Latvia'\n",
      " 'Lebanon' 'Lesotho' 'Liberia' 'Libya' 'Liechtenstein' 'Lithuania'\n",
      " 'Luxembourg' 'MS Zaandam' 'Madagascar' 'Malawi' 'Malaysia' 'Maldives'\n",
      " 'Mali' 'Malta' 'Mauritania' 'Mauritius' 'Mexico' 'Moldova' 'Monaco'\n",
      " 'Mongolia' 'Montenegro' 'Morocco' 'Mozambique' 'Namibia' 'Nepal'\n",
      " 'Netherlands' 'New Zealand' 'Nicaragua' 'Niger' 'Nigeria'\n",
      " 'North Macedonia' 'Norway' 'Oman' 'Pakistan' 'Panama' 'Papua New Guinea'\n",
      " 'Paraguay' 'Peru' 'Philippines' 'Poland' 'Portugal' 'Qatar' 'Romania'\n",
      " 'Russia' 'Rwanda' 'Saint Kitts and Nevis' 'Saint Lucia'\n",
      " 'Saint Vincent and the Grenadines' 'San Marino' 'Sao Tome and Principe'\n",
      " 'Saudi Arabia' 'Senegal' 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore'\n",
      " 'Slovakia' 'Slovenia' 'Somalia' 'South Africa' 'South Sudan' 'Spain'\n",
      " 'Sri Lanka' 'Sudan' 'Suriname' 'Sweden' 'Switzerland' 'Syria' 'Taiwan*'\n",
      " 'Tajikistan' 'Tanzania' 'Thailand' 'Timor-Leste' 'Togo'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'US' 'Uganda' 'Ukraine'\n",
      " 'United Arab Emirates' 'United Kingdom' 'Uruguay' 'Uzbekistan'\n",
      " 'Venezuela' 'Vietnam' 'West Bank and Gaza' 'Western Sahara' 'Yemen'\n",
      " 'Zambia' 'Zimbabwe']\n",
      " Number of rows stored: 53928\n",
      " Latest date is: 2020-08-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    df_code = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    \n",
    "    time_idx = pd_raw.columns[4:]\n",
    "    df_plot = pd.DataFrame({\n",
    "        'date':time_idx})\n",
    "    df_input_large= pd_raw['Country/Region'].unique()\n",
    "    for each in df_input_large:\n",
    "        df_plot[each] =np.array(pd_raw[pd_raw['Country/Region']==each].iloc[:,4::].sum(axis=0))\n",
    "    df = df_plot.drop('date', axis=1)\n",
    "    \n",
    "    #Merging the data set over COUNTRY for CODE column\n",
    "    world_raw =  pd.DataFrame({\"COUNTRY\" : df_input_large, \"Confirm cases\" :df.iloc[-1]})\n",
    "    world_con = pd.merge(world_raw, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    world_con.to_csv('data/processed/COVID_CRD.csv',sep=';',index=False)\n",
    "    \n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'COUNTRY',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model_1=pd_data_base.set_index(['state','COUNTRY']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "    pd_relational_model = pd.merge(pd_relational_model_1, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    \n",
    "    pd_relational_model.to_csv('data/processed/20200823_COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    \n",
    "    print(df_input_large)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "            date state  COUNTRY  confirmed  confirmed_filtered  confirmed_DR  \\\n",
      "31025 2020-08-18    no  Germany     228120            228165.0    145.588821   \n",
      "31026 2020-08-19    no  Germany     229706            229769.4    151.813262   \n",
      "31027 2020-08-20    no  Germany     231292            231201.6    144.833544   \n",
      "31028 2020-08-21    no  Germany     233029            232682.1    139.237035   \n",
      "31029 2020-08-22    no  Germany     233861            234162.6    181.181264   \n",
      "\n",
      "       confirmed_filtered_DR  \n",
      "31025             178.365804  \n",
      "31026             153.949953  \n",
      "31027             151.295528  \n",
      "31028             158.765201  \n",
      "31029             157.164539  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','COUNTRY',filter_on]].groupby(['state','COUNTRY']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','COUNTRY']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data=pd.read_csv('data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['COUNTRY']=='Germany'].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_result_larg[pd_result_larg['COUNTRY']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd_result_larg[pd_result_larg['COUNTRY']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visual Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal Sharbidar\\Desktop\\ADS_COVID-19\\ads_covid-19\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly import tools\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "world_con=pd.read_csv('data/processed/COVID_CRD.csv',sep=';')\n",
    "df_input_sir = pd.read_csv('data/processed/COVID_sir_fitted_table.csv',sep=';')\n",
    "df_all = df_input_sir.columns\n",
    "df_all = list(df_all)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig_2 = go.Figure()\n",
    "fig_3 =  go.Figure(data=go.Choropleth(\n",
    "                locations = world_con['CODE'],\n",
    "                z = world_con['Confirm cases'],\n",
    "                text = world_con['COUNTRY'],\n",
    "                colorscale = 'Blues',\n",
    "                autocolorscale=False,\n",
    "                reversescale=False,\n",
    "                marker_line_color='darkgray',\n",
    "                marker_line_width=0.5,\n",
    "                colorbar_title = 'Confirmed cases',\n",
    "                ))\n",
    "fig_3.update_layout(title_text='COVID 19 WORLD MAP',\n",
    "                    width=1700,\n",
    "                    height=720,\n",
    "                    geo=dict(\n",
    "                        showframe=False,\n",
    "                        showcoastlines=False,\n",
    "                        projection_type='equirectangular'\n",
    "                    ),\n",
    "                    annotations = [dict(\n",
    "                        x=0.55,\n",
    "                        y=0.1,\n",
    "                        xref='paper',\n",
    "                        yref='paper',\n",
    "                        text='World Map',\n",
    "                        showarrow = False\n",
    "                    )]\n",
    "                )\n",
    "\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.title = 'COVID-19 Dashboard'\n",
    "\n",
    "app.layout = html.Div([\n",
    "        \n",
    "        dbc.Row(dbc.Col(html.H3('Enterprise Data Science COVID-19 Data Analytics'),\n",
    "                        width={'size': 6, 'offset': 1},\n",
    "                        ),\n",
    "                ),\n",
    "        \n",
    "        dbc.Row(dbc.Col(html.Div('''\n",
    "                            Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "                            it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "                            filtering and machine learning to approximating the doubling time, and\n",
    "                            (static) deployment of responsive dashboard. \n",
    "                            '''),\n",
    "                        width={'size': 10, 'offset': 1},\n",
    "                        )\n",
    "                ),\n",
    "        \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown',\n",
    "                            options=[ {'label': each,'value':each} for each in df_input_large['COUNTRY'].unique()],\n",
    "                            value=['US', 'Germany','India'], # which are pre-selected\n",
    "                            multi= True),\n",
    "                        width={'size': 5, \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown_sir',\n",
    "                            options=[ {'label': each,'value':each} for each in df_all[1:]],\n",
    "                            value='India', # which are pre-selected\n",
    "                            multi= False\n",
    "                            ),\n",
    "                        width={'size': 5, \"offset\": 2, 'order': 'second'}\n",
    "                        ),\n",
    "                ], no_gutters=True\n",
    "        ),\n",
    "    \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                        dcc.Dropdown(\n",
    "                            id='doubling_time',\n",
    "                            options=[\n",
    "                                {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "                                {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "                                {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                                {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "                            ],\n",
    "                            value='confirmed',\n",
    "                            multi=False\n",
    "                            ),\n",
    "                        width={'size': 3, \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                \n",
    "                \n",
    "                ], \n",
    "        ),\n",
    "                \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig, \n",
    "                            id='main_window_slope'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                \n",
    "                dbc.Col(dcc.Graph(\n",
    "                            id='SIR_model'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 1, 'order': 'last'}\n",
    "                        ),\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "         dbc.Row(\n",
    "                dbc.Col(dcc.Graph(\n",
    "                            figure=fig_3,\n",
    "                            id='World_map'\n",
    "                        ),\n",
    "                        width=12, md={'size': 12,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "         )\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_dropdown', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['COUNTRY']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=800,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        ) \n",
    "    }\n",
    "\n",
    "@app.callback(\n",
    "    Output('SIR_model', 'figure'),\n",
    "    [Input('country_dropdown_sir', 'value')])\n",
    "\n",
    "def SIR_fig(con_input):\n",
    "    df= df_input_sir\n",
    "    \n",
    "    for i in df[1:]:\n",
    "        data = []\n",
    "        trace = go.Scatter(x=df.date,\n",
    "                        y=df[con_input],\n",
    "                        mode='lines+markers',\n",
    "                        name = con_input)\n",
    "        data.append(trace)\n",
    "        \n",
    "        trace_fitted = go.Scatter(x=df.date,\n",
    "                        y=df[con_input +'_fitted'], \n",
    "                        mode='lines+markers',\n",
    "                        name=con_input+'_fitted')\n",
    "        data.append(trace_fitted)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return {'data': data,\n",
    "            'layout' : dict(\n",
    "                width=800,\n",
    "                height=720,\n",
    "                title= 'SIR model',\n",
    "                xaxis={'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "                yaxis={'type':\"log\",\n",
    "                       'range':'[1.1,5.5]'\n",
    "                      }\n",
    "                \n",
    "            )\n",
    "        }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, port= 8051, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
